<!DOCTYPE html>
<html>
<head>
	<title></title>

<style>
p {
  display: block;
  margin-top: 1em;
  margin-bottom: 1em;
  margin-left: 2em;
  margin-right: 2em;
  font-size: 19px;
  line-height: 1.8;
}
</style>

</head>
<body>
<center>
	
	<h1> Paper Review of (The Case for Learned Index Structures) </h1>
</center>
<p>
	In traditional search index, we have B-Tree, BitMap, and Hash-Table for mapping keys to records. See Figures below.
</p>

<center>	
	<img src="bitmap.png" alt="BitMap" > <br>
	<img src="btree.png" alt="B tree"> <br>
	<img src="hash.png" alt="Hash"> <br>
</center>

<p>
	These algorithms are models. Instead of these traditional ways of exploring index for a specific record, the deep learning model can replace most of the traditional models. Models learn how the structure for dataset looks like and figure out where the record located. Hence learned index. Models may learn the sort order or the structure of lookup keys and use them in prediction. The experiment shows that neural net outperforms B-Tree by 70% improvement in speed while saying an order of magnitude in memory. 


	Index is a general purpose data structure. 

	All indexes that used in a database have not assumed anything about data distribution and thus did not take advantage of common patterns in real-world examples.

	Here an example that demonstrates the difference between using B-Tree over the key and the key as an offset which result in O(1) instead of O(n). Also, memory size will be reduced from O(n) to O(1).


	So, knowing data distribution enables highly optimizing.


	Also, they will use the advantage of the hardware that the ML model will have such GPU and TPU.



	The main contribution is that outlining and evaluating the potential of a novel approach of building indexes and decomposing data structure into o learned model.


	A rank index structures like B-Trees are models a given key and they predict the location of a value within a key-sorted set, as shown n the figure.
</p>
	<center>
			<img src="Btree_LearnedModel.png" alt="Learned">
	</center>
<p>

	In the ML modeling index, the model (such as neural nets) tries to transfer the key to  position with a max-min error range from 0 to the maximum length of the page. 

	For stored data, ML model is provides guaranttee but not on stored data.

</p>
<p>
	Range index models are CDF Models. 
	<br> <center> p = F(Key) &#215; N </center>

</p>
	Here, the paper start with Naive Learning Index. It has two layers fully connected neural network with activation function RELU by using Tensorflow and Python. 
	Performance:
	ToDo...

	This naive approach limited because of 
	<ul>
		<li> Overhead </li>
		<li> Accuracy </li>
		<li> No cache efficient </li>
	</ul>
<p>
	
	<p>
		To overcome the challenges and to replace the index with model, paper develop the learning index framework (LIF), recursive model indexes (RMI), and standard error based search strategies.
		LIF, given index specification, LIF generates different index configurations, optimize them and test them automatically. LIF relies on NN to learn model. Given LIF Tensorflow model, it LIF extracts all weights from the model and generates efficent index structures in C++ based on model specification. As a result, 30 nano seconds was the time of execution. It's still an experimental framework. 

	</p>

	<p>

		The recursive model index. One of the challenges is the accuracy. Reducing preduction error to order of hundreds from 100M records using single model is difficult. At the same time reducing error from 10K from 100M is easier to achive when replacing two layers of B-Tree with a 2-layer model.  
	</p>
		
		<center><img src="staged.png"></center>
	<p>
		
		This paper built a hierarchy of the models where at each stage the model takes the key as an input and based on it picks another model, until the final stage predicts the position. F(x) where x is the key and y 	&isin; [0,N) the position. The stage L will have M<sub>L</sub> Models. Model at stage 0, F<sub>0</sub>(x)&asymp;y.

		<center><img src="l.png"></center>

		Benefits:
		1- make separation between model size and complexity from execution cost. 
		2- Learning overall shape from data distribution.
		3- Divide the space to sub-spaces.
		4- There is no search process for next model.
	</p>

	<p>
		
		Hybrid Indexes.
		<center><img src="Hybrid.png"></center>

		Model Biased Search -- > The first middle point is set to the value predicted by the model as default.
		Biased Quaternary Search --> pos - &sigma; , pos, pos + &sigma;.
	</p>

</p>

	<p>
		Indexing Strings 


	</p>

	<p>
		Training
		It's not primary part of the paper 		
	</p>

	<p>
		Results and comparison in terms of space and speed. 
		Integer Dataset 
		String Dataset

	</p>

	<p>
		Point Index. Example of point index is hash-maps that use a hash-function. 
		The hash-model index is based on CDF. 

	</p>

	<p>
		Existence Index such as Bloom filters. 
		image 9 a

		learned bloom filters
		
	</p>
<h3> References: </h3>
<ol>
<li> <a href="https://www.youtube.com/watch?v=NaqJO7rrXy0&t=2890s">Stanford Seminar - The Case for Learned Index Structures</a> </li>
<li> <a href="https://arxiv.org/pdf/1712.01208.pdf">The Case for Learned Index Structures- White Paper</a> </li>
<li> <a href="https://blog.acolyer.org/2019/01/16/sagedb-a-learned-database-system/">The Morning Paper</a> </li>
<li> <a href="https://millyz.github.io/blog/posts/sagedb-cidr19/">SageDB:A Learned Database System, CIDR19
</a> </li>
<li> <a href="http://www.odbms.org/blog/2018/12/on-learned-index-structures-interview-with-alex-beutel/">On Learned Index Structures. Interview with Alex Beutel
</a> </li>
<li> <a href="https://www.youtube.com/watch?v=mkIHC7xMSRQ">Learned Index Structures</a> </li>
<li> <a href="https://www.youtube.com/watch?v=0q9mxMekBeE">Berlin Buzzwords 2018: Robert Rodger â€“ Learned Indexes: a New Idea for Efficient Data Access
</a> </li>
<li> <a href="https://medium.com/@rod_83597/learned-multidimensional-indexes-171c93fb581a">Learned Multidimensional Indexes
</a> </li>
<li> <a href="https://www.youtube.com/watch?v=7MfWqoLxSeo&t=814s"> Saama TechTalk - Learned Index
</a> </li>
<li> <a href="https://www.slideshare.net/ssuser9ebf46/the-case-for-learned-index-structures-102294912
"> Presentation on slide share. </a></li>
<li> <a href="https://towardsdatascience.com/what-if-i-told-you-database-indexes-could-be-learned-6cf8f59bff94"> What if I told you database indexes could be learned?</a> </li>
</ol>

</body>

</html>
